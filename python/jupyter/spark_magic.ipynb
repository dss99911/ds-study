{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "https://github.com/jupyter-incubator/sparkmagic\n",
    "\n",
    "jupyter notebook에서 spark magic이라는 클라이언트 라이브러리를 통해서\n",
    "spark server에 설치된 Livy를 통해 job요청을 할 수 있음.\n",
    "\n",
    "https://livy.incubator.apache.org/get-started/\n",
    "로컬에서 서버에 Livy를 통해 직접 접근하는 것은 안전하지 않아. 인증 단계를 추가하는게 좋음.\n",
    "로컬에 Livy를 설치 시도 해봤으나,\n",
    "\n",
    "repl jar가 없다는 에러\n",
    "- scala 2.11을 설치하면 해결됨.\n",
    "- brew install scala@2.11\n",
    "\n",
    "spark 실행시 에러\n",
    "- http://localhost:8998/ 의 세션 로그에 아래와 같은 에러 발생\n",
    "- 버전 문젠가 하여, livy를 scala 2.12로 빌드해봤지만 여전히 동일한 문제 발생\n",
    "- scala-compiler jar파일을 확인해봤을 때, scala.tools.nsc.Settings.usejavacp 가 포함된 class파일은 존재했음\n",
    "```\n",
    "java.lang.NoSuchMethodError: scala.tools.nsc.Settings.usejavacp()Lscala/tools/nsc/settings/AbsSettings$AbsSetting\n",
    "at org.apache.livy.repl.SparkInterpreter.start(SparkInterpreter.scala:52)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "!pip install sparkmagic"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ""
     ]
    }
   ],
   "source": [
    "!pip install sparkmagic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enabling notebook extension jupyter-js-widgets/extension...\r\n",
      "      - Validating: \u001B[32mOK\u001B[0m\r\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbextension enable --py --sys-prefix widgetsnbextension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
      "name": "#%%\n"
     ]
    }
   ],
   "source": [
    "!pip show sparkmagic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__init__.py     kernelmagics.py \u001B[1m\u001B[36msparkkernel\u001B[m\u001B[m     \u001B[1m\u001B[36mwrapperkernel\u001B[m\u001B[m\r\n",
      "\u001B[1m\u001B[36m__pycache__\u001B[m\u001B[m     \u001B[1m\u001B[36mpysparkkernel\u001B[m\u001B[m   \u001B[1m\u001B[36msparkrkernel\u001B[m\u001B[m\r\n"
     ]
    }
   ],
   "source": [
    "!ls /Users/hyun.kim/anaconda3/envs/spark-study2/lib/python3.9/site-packages/sparkmagic/kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[InstallKernelSpec] Installed kernelspec sparkkernel in /usr/local/share/jupyter/kernels/sparkkernel\r\n",
      "[InstallKernelSpec] Installed kernelspec pysparkkernel in /usr/local/share/jupyter/kernels/pysparkkernel\r\n",
      "[InstallKernelSpec] Installed kernelspec sparkrkernel in /usr/local/share/jupyter/kernels/sparkrkernel\r\n"
     ]
    }
   ],
   "source": [
    "# Install the wrapper kernels\n",
    "!jupyter-kernelspec install /Users/hyun.kim/anaconda3/envs/spark-study2/lib/python3.9/site-packages/sparkmagic/kernels/sparkkernel\n",
    "!jupyter-kernelspec install /Users/hyun.kim/anaconda3/envs/spark-study2/lib/python3.9/site-packages/sparkmagic/kernels/pysparkkernel\n",
    "!jupyter-kernelspec install /Users/hyun.kim/anaconda3/envs/spark-study2/lib/python3.9/site-packages/sparkmagic/kernels/sparkrkernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!jupyter serverextension enable --py sparkmagic\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The code failed because of a fatal error:\n",
      "\tSession 0 did not start up in 60 seconds..\n",
      "\n",
      "Some things to try:\n",
      "a) Make sure Spark has enough available resources for Jupyter to create a Spark context.\n",
      "b) Contact your Jupyter administrator to make sure the Spark magics library is configured correctly.\n",
      "c) Restart the kernel.\n"
     ]
    }
   ],
   "source": [
    "print(1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Apache Livy\n",
    "spark magic"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}