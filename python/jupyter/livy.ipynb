{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Apache Livy\n",
    "https://livy.incubator.apache.org/get-started/\n",
    "mac에 설치시 repl jar가 없다는 에러 남\n",
    "scala 2.11을 설치해도 안됨(2.12를 지우면 되지 않을까??)\n",
    "brew install scala@2.11\n",
    "\n",
    "livy를 scala 2.12로 설치하면 실행은 되지만,\n",
    "spark 실행시 livy session 에러남 (scala.tools.nsc.Settings.usejavacp 존재하지 않는 다는 에러)\n",
    "scala-compiler jar파일을 확인해봤을 때, scala.tools.nsc.Settings.usejavacp 가 포함된 class파일은 존재했음\n",
    "\n",
    "일단 EMR cluster에는 Livy가 설치되어 있으므로 패스.\n",
    "\n",
    "\n",
    "## SparkMagic\n",
    "Jupyter notebook에서 livy를 통해 spark를 바로 호출하는 방법\n",
    "https://github.com/jupyter-incubator/sparkmagic\n",
    "\n",
    "python 3.9에서 kernel실행시 아래 에러나서, 3.7에서 했을 때, 정상 작동\n",
    "```'coroutine' object is not subscriptable```\n",
    "\n",
    "~/.sparkmagic/conf.json 에 cluster ip설정 필요\n",
    "\n",
    "## notebook\n",
    "jupyter notebook에서 spark magic이라는 클라이언트 라이브러리를 통해서 spark server에 설치된 Livy를 통해 job요청을 할 수 있음.\n",
    "job 진행 상황 및 spark ui 링크등을 보여줌\n",
    "zeppelin의 경우 %livy.spark 등으로 진행상황등 파악 가능\n",
    "\n",
    "## run spark on local Mac\n",
    "- livy가 mac local에서 제대로 작동하지 않아. 임시로 아래 방법을 쓰면 좋을 듯\n",
    "### find spark home\n",
    "```\n",
    "sc.getConf.get(\"spark.home\")\n",
    "```\n",
    "\n",
    "### add env variable\n",
    "```\n",
    "export SPARK_HOME=/Users/hyun.kim/anaconda3/envs/spark-study2/lib/python3.9/site-packages/pyspark\n",
    "export HADOOP_HOME=/Users/hyun.kim/anaconda3/envs/spark-study2/lib/python3.9/site-packages/pyspark\n",
    "```\n",
    "\n",
    "### install spark scala kernel\n",
    "```\n",
    "pip install spylon-kernel\n",
    "python -m spylon_kernel install\n",
    "```\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP/1.1 200 OK\r\n",
      "\u001B[1mDate\u001B[0m: Sat, 23 Apr 2022 13:38:53 GMT\r\n",
      "\u001B[1mContent-Type\u001B[0m: application/json;charset=utf-8\r\n",
      "\u001B[1mContent-Length\u001B[0m: 34\r\n",
      "\u001B[1mServer\u001B[0m: Jetty(9.3.24.v20180605)\r\n",
      "\r\n",
      "{\"from\":0,\"total\":0,\"sessions\":[]}"
     ]
    }
   ],
   "source": [
    "!curl -H \"Content-Type: application/json\" -i http://localhost:8998/sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "server_ip = 'http://localhost'\n",
    "session_id = 8830\n",
    "headers = {'Content-Type': 'application/json'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 8830,\n",
       " 'name': None,\n",
       " 'appId': None,\n",
       " 'owner': None,\n",
       " 'proxyUser': None,\n",
       " 'state': 'starting',\n",
       " 'kind': 'spark',\n",
       " 'appInfo': {'driverLogUrl': None, 'sparkUiUrl': None},\n",
       " 'log': ['stdout: ', '\\nstderr: ', '\\nYARN Diagnostics: ']}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create session\n",
    "# curl -H \"Content-Type: application/json\" -X POST -d '{\"kind\":\"spark\"}' -i http://localhost:8998/sessions\n",
    "\n",
    "data = {'kind': 'spark'}\n",
    "url = f'{server_ip}:8998/sessions'\n",
    "response = requests.post(url, data=json.dumps(data), headers=headers)\n",
    "response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# list livy sessions\n",
    "# curl -H \"Content-Type: application/json\" -i http://localhost:8998/sessions\n",
    "\n",
    "url = f'{server_ip}:8998/sessions'\n",
    "response = requests.get(url, headers=headers)\n",
    "response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# get a livy session\n",
    "# curl -H \"Content-Type: application/json\" -i http://localhost:8998/sessions/8830\n",
    "\n",
    "\n",
    "url = f'{server_ip}:8998/sessions/{session_id}'\n",
    "response = requests.get(url, headers=headers)\n",
    "response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 0,\n",
       " 'code': 'println(sc.parallelize(1 to 5).collect())',\n",
       " 'state': 'waiting',\n",
       " 'output': None,\n",
       " 'progress': 0.0,\n",
       " 'started': 0,\n",
       " 'completed': 0}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# submit job\n",
    "# curl -H \"Content-Type: application/json\" -X POST -d '{\"code\":\"println(sc.parallelize(1 to 5).collect())\"}' -i http://localhost:8998/sessions/0/statements\n",
    "\n",
    "data = {'code': 'println(sc.parallelize(1 to 5).collect())'}\n",
    "url = f'{server_ip}:8998/sessions/{session_id}/statements'\n",
    "response = requests.post(url, data=json.dumps(data), headers=headers)\n",
    "response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 0,\n",
       " 'code': 'println(sc.parallelize(1 to 5).collect())',\n",
       " 'state': 'available',\n",
       " 'output': {'status': 'ok',\n",
       "  'execution_count': 0,\n",
       "  'data': {'text/plain': '[I@12a0d40b\\n'}},\n",
       " 'progress': 1.0,\n",
       " 'started': 1650722071248,\n",
       " 'completed': 1650722076537}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get job output\n",
    "# curl -H \"Content-Type: application/json\" -i http://localhost:8998/sessions/0/statements/0\n",
    "url = f'{server_ip}:8998/sessions/{session_id}/statements/0'\n",
    "response = requests.get(url, headers=headers)\n",
    "response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'msg': 'deleted'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# delete session\n",
    "# curl -H \"Content-Type: application/json\" -X DELETE -d -i http://localhost:8998/sessions/0\n",
    "url = f'{server_ip}:8998/sessions/{session_id}'\n",
    "response = requests.delete(url, headers=headers)\n",
    "response.json()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Spark",
   "language": "scala",
   "name": "sparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}